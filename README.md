\##â€¯ğŸ“Â Architecture & DesignÂ (Why it looks the way it does)

| Layer                | Key Decisions                                                                                                                             | Meets Assignment Items                      |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------- |
| **Transport**        | EchoÂ v4 + custom JWT middleware.<br>Swagger comments generate the OpenAPI spec automatically (`swag init`).                               | *â€œAPI endpoints + security middlewareâ€*     |
| **Service**          | Pure Go interface; orchestrates *repositoryÂ â†”Â cache* inside an explicit transaction, then updates Redis (*cacheâ€‘aside*).                  | *Proper concurrency, clean code separation* |
| **Repository**       | **pgx + sqlc** â†’ typeâ€‘safe, zero ORM overhead.<br>`internal/repository/pg` hides SQL; interfaces live in `internal/repository`.           | *â€œPostgreSQL schema & query optimisationâ€*  |
| **Cache**            | **goâ€‘redis** helper; 5â€‘minute TTL, cacheâ€‘aside; invalidated by writers.                                                                   | *â€œRedis caching strategyâ€*                  |
| **Stream**           | Two goroutines: `Generator` (producer) and `Start` (consumer). They communicate via a buffered channel to keep backâ€‘pressure predictable. | *â€œUse of Goâ€™s concurrency modelâ€*           |
| **Observability**    | `slog` structured logs, Echo requestâ€‘logger, optional Prometheus middleware.                                                              | *â€œLogging & Observabilityâ€*                 |
| **CI Tests**         | pgxmock + miniredis + tableâ€‘driven tests give deterministic unit coverage without real infra.                                             | *â€œUnit testing with tableâ€‘driven approachâ€* |
| **Containerisation** | Multiâ€‘stage `Dockerfile` (distroless) + oneâ€‘shot `migrate` job in `dockerâ€‘compose.yml`.                                                   | *â€œSetup instructions (dockerâ€‘compose up)â€*  |

<small>See the **diagram in `docs/architecture.svg`** for a visual of dataâ€‘flow from HTTPâ€¯â†’â€¯serviceâ€¯â†’â€¯DB|Redisâ€¯â†’â€¯client.</small>

---

\##â€¯ğŸš€Â QuickÂ StartÂ (Setup & Running Locally)

```bash
# 0ï¸âƒ£ clone and prepare envâ€‘file
git clone <yourâ€‘repo> && cd fleet-tracker
cp .env.example .env            # edit values as you like

# 1ï¸âƒ£ spin up everything
docker compose up -d --build    # Postgres, Redis, migrations, API

# 2ï¸âƒ£ tail logs â€“ you should see â€œstream update â€¦â€
docker compose logs -f api

# 3ï¸âƒ£ grab a JWT for testing
TOKEN=$(make token)             # or: go run ./cmd/token -sub dev

# 4ï¸âƒ£ call the API
curl -H "Authorization: Bearer $TOKEN" \
     "http://localhost:8080/api/vehicle/status?id=d9c1b442-fb2f-412a-9d2a-a3ab499cd91c" | jq
```

| Task                     | Command                                                       |
| ------------------------ | ------------------------------------------------------------- |
| **Run unit tests**       | `go test ./... -race -cover`                                  |
| **Generate Swagger**     | `swag init` âœ open `http://localhost:8080/swagger/index.html` |
| **Shut everything down** | `docker compose down -v`                                      |

---

\##â€¯ğŸ—„ï¸Â Database Schema & Index Rationale

```sql
-- vehicle table
CREATE TABLE vehicle (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    plate_number TEXT UNIQUE NOT NULL,
    last_status  JSONB NOT NULL
);

-- trips table
CREATE TABLE trips (
    id         UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    vehicle_id UUID NOT NULL REFERENCES vehicle(id) ON DELETE CASCADE,
    start_time TIMESTAMPTZ NOT NULL,
    end_time   TIMESTAMPTZ,
    mileage    DOUBLE PRECISION,
    avg_speed  DOUBLE PRECISION
);

-- â¬‡ï¸ this multiâ€‘column index is critical for the â€œpast 24â€¯hâ€ query
CREATE INDEX idx_trips_vehicle_time
          ON trips (vehicle_id, start_time DESC);
```

\###Â EXPLAINÂ ANALYZE proof

> **Insert the screenshot or copyâ€‘paste here** after you run the query below on a dataset with \~500â€¯k rows.

```sql
EXPLAIN ANALYZE
SELECT *
  FROM trips
 WHERE vehicle_id = 'd9c1b442-fb2f-412a-9d2a-a3ab499cd91c'
   AND start_time >= NOW() - INTERVAL '24 hours'
 ORDER BY start_time DESC;
```

<details>
<summary>Sample output (text)</summary>

```
Index Scan using idx_trips_vehicle_time on trips  (cost=0.43..12.88 rows=3 width=65) 
  Index Cond: ((vehicle_id = 'd9c1b442-fb2f-412a-9d2a-a3ab499cd91c'::uuid)
               AND (start_time >= (now() - '24:00:00'::interval)))
Planning Time: 0.25 ms
Execution Time: 0.13 ms
```

</details>

Add a PNGâ€‘orâ€‘SVG capture of the full **`EXPLAIN ANALYZE`** in
`docs/img/explain_trips_24h.png`, then embed like:

```markdown
![Query plan for pastâ€‘24â€¯h trips](docs/img/explain_trips_24h.png)
```

---

\##â€¯ğŸ›¡ï¸Â Security â€“Â JWT Flow for Local Dev

1. **Mint token**

   ```bash
   go run ./cmd/token -sub alice -exp 24h  # uses $JWT_SIGN_KEY
   ```
2. **Send with requests**
   `Authorization: Bearer <token>`
3. **Middleware** validates HS256 signature and puts claims in `echo.Context` under key `claims`.

---

\##â€¯ğŸ§ªÂ Testing Strategy

* **Repositories** â€” pgxmock (DB) & tableâ€‘driven cases.
* **Cache** â€” miniredis, TTL fastâ€‘forward.
* **Stream** â€” fake service that counts `Ingest` calls under `context.WithTimeout`.

Run everything with plain `go test`; no Docker or external services required â†’ ğŸ’¯ portability.

---

\##â€¯ğŸŒÂ SampleÂ cURL Collection

| Purpose               | Command                                                                                                                                                                                                                                      |
| --------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| *Get current status*  | `curl -H "Authorization: Bearer $TOKEN" "http://localhost:8080/api/vehicle/status?id=<uuid>"`                                                                                                                                                |
| *Trip history (24â€¯h)* | `curl -H "Authorization: Bearer $TOKEN" "http://localhost:8080/api/vehicle/trips?id=<uuid>"`                                                                                                                                                 |
| *Manual ingest*       | `curl -X POST -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" -d '{"vehicle_id":"<uuid>","status":{"location":[55.29,25.27],"speed":42,"timestamp":"2025-06-25T12:00:00Z"}}' http://localhost:8080/api/vehicle/ingest` |

Import the Postman collection in `docs/postman_collection.json` for easier exploration.

---

\##â€¯ğŸ“‹Â Design Tradeâ€‘offs & Future Work

* **Why cacheâ€‘aside?**
  Simpler failure mode: if Redis is down, the API degrades gracefully by hitting Postgres.
* **Single vehicle only (assignment scope)** â€” extend by sharding trips by `vehicle_id` or using timeâ€‘series DB.
* **Observability** â€” metrics endpoint ready; add Grafana dashboard in `docker-compose.override.yml`.
* **CI/CD** â€” `.github/workflows/ci.yml` builds image, runs unit tests, and pushes to GHÂ ContainerÂ Registry.

---

\##â€¯ğŸ™ŒÂ Contributing

1. Fork â†’ create feature branch â†’ PR.
2. `make test && make lint` must pass.
3. Two approving reviews trigger autoâ€‘merge.

---
